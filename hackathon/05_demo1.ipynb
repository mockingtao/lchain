{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime\n",
    "\n",
    "from apikey import API_KEY, BASE_URL, DEPLOYMENT_NAME\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from langchain.prompts.chat import(\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate\n",
    ")\n",
    "\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "\n",
    "from langchain.schema import (\n",
    "    SystemMessage,\n",
    "    HumanMessage,\n",
    "    AIMessage\n",
    "    )\n",
    "\n",
    "from langchain.chains import LLMChain, APIChain, SequentialChain, SimpleSequentialChain\n",
    "\n",
    "import os \n",
    "from apikey import apikey \n",
    "\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = apikey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo-0613', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info1 = f\"\"\"\n",
    "dataset name: 行业市场变化_市场大盘分析_行业市场大盘_魔镜\n",
    "\n",
    "dataset description:\n",
    "primary keys:[月份, 类目编码]\n",
    "3540 rows\n",
    "| field | type | uniques | nan_percentage | max | min |\n",
    "| --- | --- | --- | --- | --- | --- |\n",
    "| 月份 | DateTime | 59 | 0.0 | nan | nan |\n",
    "| 平台编码 | String | 2 | 0.0 | nan | nan |\n",
    "| 一级类目 | String | 4 | 0.0 | nan | nan |\n",
    "| 类目编码 | Numeric | 60 | 0.0 | 39264.0 | 10209.0 |\n",
    "| 销售额 | Numeric | 3540 | 0.0 | 99989.30547 | 1.8873 |\n",
    "| 销量 | Numeric | 974 | 0.0 | 999.0 | 0.0 |\n",
    "| 店铺数 | Numeric | 181 | 0.0 | 200.0 | 20.0 |\n",
    "| 商品数 | Numeric | 451 | 0.0 | 500.0 | 50.0 |\n",
    "| 会员数量 | Numeric | 1 | 0.0 | 0.0 | 0.0 |\n",
    "\"\"\"\n",
    "data_info2 = f\"\"\"\n",
    "dataset name: 行业市场变化_市场大盘分析_行业市场大盘_魔镜\n",
    "\n",
    "dataset description:\n",
    "primary keys:[月份, 类目编码]\n",
    "3540 rows\n",
    "| field | type | uniques | nan_percentage | max | min |\n",
    "| --- | --- | --- | --- | --- | --- |\n",
    "| 月份 | DateTime | 59 | 0.0 | nan | nan |\n",
    "| 平台编码 | String | 2 | 0.0 | nan | nan |\n",
    "| 一级类目 | String | 4 | 0.0 | nan | nan |\n",
    "| 二级类目 | String | 8 | 6.666666666666667 | nan | nan |\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "data_info = data_info1 + data_info2\n",
    "\n",
    "# 当前时间\n",
    "today = date.today()\n",
    "formatted_date = today.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "today_dt = datetime.now()\n",
    "formatted_dt = today_dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "formatted_dt\n",
    "\n",
    "\n",
    "api_params = \"\"\"\n",
    "{\n",
    "    \"chartType\":\"\", // 图表类型，可选的图表类型有\n",
    "    \"row\": // 维度字段，每个维度用一个字典表示{\"name\":\"字段1\"}\n",
    "    [ \n",
    "        {\n",
    "            \"name\":\"A\"\n",
    "        }\n",
    "    ],\n",
    "    \"filters\":[ //\n",
    "        {\n",
    "            \"name\":\"A\",\n",
    "            \"filterType\":\"IN\",\n",
    "            \"filterValue\":[\n",
    "                \"\",\n",
    "                \"\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\":\"A\",\n",
    "            \"filterType\":\"GT\",\n",
    "            \"filterValue\":[\n",
    "                \"\"\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"metric\":[\n",
    "        {\n",
    "            \"name\":\"A\",\n",
    "            \"aggrType\":\"SUM\"\n",
    "        },\n",
    "        {\n",
    "\n",
    "        }\n",
    "    ],\n",
    "    \"sorting\":[\n",
    "        {\n",
    "            \"name\":\"A\",\n",
    "            \"aggrType\":\"SUM\",\n",
    "            \"ordering\":\"desc\"\n",
    "        },\n",
    "        {\n",
    "\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure 无function功能，暂时先用openai接口\n",
    "# chat_llm = AzureChatOpenAI(\n",
    "#     openai_api_base=BASE_URL,\n",
    "#     openai_api_version=\"2023-05-15\",\n",
    "#     deployment_name=DEPLOYMENT_NAME,\n",
    "#     openai_api_key=API_KEY,\n",
    "#     openai_api_type = \"azure\",\n",
    "#     temperature=0\n",
    "# )\n",
    "\n",
    "chat_llm = ChatOpenAI(temperature=0.0, model= 'gpt-3.5-turbo-0613')\n",
    "chat_llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='我喜欢编程。 (Wǒ xǐhuān biānchéng.)', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "chat_llm([HumanMessage(content=\"Translate this sentence from English to Chinese. I love programming.\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Promp Eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘图function：\n",
    "# functions=[\n",
    "#       {\n",
    "#         \"name\": SkillFunctions.SendEmail.value,\n",
    "#         \"description\": \"send email assistant\",\n",
    "#         \"parameters\": {\n",
    "#           \"type\": \"object\",\n",
    "#           \"properties\": {\n",
    "#             \"receiver\": {\n",
    "#               \"type\": \"string\",\n",
    "#               \"description\": \"email receiver\",\n",
    "#             },\n",
    "#             \"content\": {\"type\": \"string\", \"description\": \"email content\"},\n",
    "#           },\n",
    "#           \"required\": [\"receiver\", \"content\"],\n",
    "#         },\n",
    "#       }\n",
    "#     ]\n",
    "\n",
    "functions = [\n",
    "    {\n",
    "        \"name\" : \"draw_function\",\n",
    "        \"description\" : \"core filed for drawing a chart by deterministic data\",\n",
    "        \"parameters\" : {\n",
    "            \"type\" : \"object\",\n",
    "            \"properties\" :{\n",
    "                \"row\": {\n",
    "                    \"type\" : \"array\",\n",
    "                    \"description\" : \"Data dimension field\",\n",
    "                    \"properties\" :{\n",
    "                        \"name\":{\n",
    "                            \"type\" : \"string\",\n",
    "                            \"description\" : \"dimension field name\"\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"filter\" :{\n",
    "                    \"type\" : \"array\",\n",
    "                    \"description\" : \"Data filter field\",\n",
    "                    \"properties\" :{\n",
    "                        \"filterType\":{\n",
    "                            \"type\" : \"string\",\n",
    "                            \"description\" : \"filter type.For example, BT means between, \\\n",
    "                              GT means Greater Than.This is an enumeration value, \\\n",
    "                                the optional values are BT,GT,GE,LT,LE,EQ,NE,IN,NI,\"\n",
    "                        },\n",
    "                        \"filterValue\":{\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"value to compare.Two elements when filterType is BT. \\\n",
    "                              Multiple elements when filterType is IN or NI. \\\n",
    "                                One element when filterType is other.\"\n",
    "                        }\n",
    "                    }\n",
    "\n",
    "                }\n",
    "            }\n",
    "\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__str__ returned non-string (type list)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m message \u001b[39m=\u001b[39m chat_llm\u001b[39m.\u001b[39;49mpredict_messages([HumanMessage(content\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mhello\u001b[39;49m\u001b[39m'\u001b[39;49m)], functions\u001b[39m=\u001b[39;49mfunctions)\n\u001b[1;32m      2\u001b[0m message\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chat_models/base.py:245\u001b[0m, in \u001b[0;36mBaseChatModel.predict_messages\u001b[0;34m(self, messages, stop, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m     _stop \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(stop)\n\u001b[0;32m--> 245\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(messages, stop\u001b[39m=\u001b[39;49m_stop, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chat_models/base.py:195\u001b[0m, in \u001b[0;36mBaseChatModel.__call__\u001b[0;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m    189\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    190\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    194\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BaseMessage:\n\u001b[0;32m--> 195\u001b[0m     generation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m    196\u001b[0m         [messages], stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    197\u001b[0m     )\u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m    198\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(generation, ChatGeneration):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chat_models/base.py:95\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[0;32m---> 95\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m     96\u001b[0m llm_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_combine_llm_outputs([res\u001b[39m.\u001b[39mllm_output \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chat_models/base.py:87\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 87\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[1;32m     88\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(m, stop\u001b[39m=\u001b[39mstop, run_manager\u001b[39m=\u001b[39mrun_manager, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     89\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m     90\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(m, stop\u001b[39m=\u001b[39mstop)\n\u001b[1;32m     91\u001b[0m         \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m messages\n\u001b[1;32m     92\u001b[0m     ]\n\u001b[1;32m     93\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chat_models/base.py:88\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[0;32m---> 88\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(m, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     89\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m     90\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(m, stop\u001b[39m=\u001b[39mstop)\n\u001b[1;32m     91\u001b[0m         \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m messages\n\u001b[1;32m     92\u001b[0m     ]\n\u001b[1;32m     93\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chat_models/openai.py:354\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[39mreturn\u001b[39;00m ChatResult(generations\u001b[39m=\u001b[39m[ChatGeneration(message\u001b[39m=\u001b[39mmessage)])\n\u001b[0;32m--> 354\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompletion_with_retry(messages\u001b[39m=\u001b[39;49mmessage_dicts, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    355\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chat_models/openai.py:302\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 302\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m     \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chat_models/openai.py:300\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    299\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 300\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    138\u001b[0m (\n\u001b[1;32m    139\u001b[0m     deployment_id,\n\u001b[1;32m    140\u001b[0m     engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m     api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m )\n\u001b[0;32m--> 153\u001b[0m response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m     url,\n\u001b[1;32m    156\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m     request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m     request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m )\n\u001b[1;32m    163\u001b[0m \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m     \u001b[39m# must be an iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    216\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m     method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m     url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m     request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m )\n\u001b[0;32m--> 226\u001b[0m resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/openai/api_requestor.py:620\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    619\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 620\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    623\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    624\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    625\u001b[0m         ),\n\u001b[1;32m    626\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    627\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/openai/api_requestor.py:683\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 683\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    684\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31m<class 'str'>\u001b[0m: (<class 'TypeError'>, TypeError('__str__ returned non-string (type list)'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2113\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2110\u001b[0m     traceback\u001b[39m.\u001b[39mprint_exc()\n\u001b[1;32m   2111\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2113\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_showtraceback(etype, value, stb)\n\u001b[1;32m   2114\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_pdb:\n\u001b[1;32m   2115\u001b[0m     \u001b[39m# drop into debugger\u001b[39;00m\n\u001b[1;32m   2116\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdebugger(force\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/ipykernel/zmqshell.py:541\u001b[0m, in \u001b[0;36mZMQInteractiveShell._showtraceback\u001b[0;34m(self, etype, evalue, stb)\u001b[0m\n\u001b[1;32m    535\u001b[0m sys\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mflush()\n\u001b[1;32m    536\u001b[0m sys\u001b[39m.\u001b[39mstderr\u001b[39m.\u001b[39mflush()\n\u001b[1;32m    538\u001b[0m exc_content \u001b[39m=\u001b[39m {\n\u001b[1;32m    539\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtraceback\u001b[39m\u001b[39m\"\u001b[39m: stb,\n\u001b[1;32m    540\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mename\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mstr\u001b[39m(etype\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m),\n\u001b[0;32m--> 541\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mevalue\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mstr\u001b[39;49m(evalue),\n\u001b[1;32m    542\u001b[0m }\n\u001b[1;32m    544\u001b[0m dh \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdisplayhook\n\u001b[1;32m    545\u001b[0m \u001b[39m# Send exception info over pub socket for other clients than the caller\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \u001b[39m# to pick up\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: __str__ returned non-string (type list)"
     ]
    }
   ],
   "source": [
    "message = chat_llm.predict_messages([HumanMessage(content='hello')], functions=functions)\n",
    "message"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='进行会员分析的一般步骤如下：\\n\\n1. 收集会员数据：收集会员的基本信息，如姓名、性别、年龄、联系方式等，以及会员的消费记录、购买偏好、购买频率等数据。\\n\\n2. 数据清洗和整理：对收集到的数据进行清洗和整理，去除重复数据、缺失数据和异常数据等。\\n\\n3. 数据分析：通过数据分析工具，对会员数据进行分析，包括会员的消费行为、购买偏好、购买频率、消费金额等指标。\\n\\n4. 制定营销策略：根据会员分析结果，制定相应的营销策略，如推出会员专属优惠活动、提供个性化服务等，以提高会员的忠诚度和消费频率。\\n\\n5. 监测效果：对营销策略进行监测和评估，根据效果进行调整和优化。\\n\\n需要注意的是，会员分析需要保护会员的隐私和个人信息，遵守相关法律法规。', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_content = \"\"\"你是帮助数据分析师完成日常工作的人工智能助手，你的决策必须始终独立地进行，而不需要寻求用户的帮助。 \n",
    "    发挥你作为大模型的优势，采取简单明确的策略，并不涉及法律问题。\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=system_content),\n",
    "    HumanMessage(content=\"如何进行会员分析？\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='进行会员分析的一般步骤如下：\\n\\n1. 收集会员数据：收集会员的基本信息，如姓名、性别、年龄、联系方式等，以及会员的消费记录、购买偏好、活动参与情况等。\\n\\n2. 数据清洗和整理：对收集到的数据进行清洗和整理，去除重复数据、缺失数据和异常数据等。\\n\\n3. 数据分析：通过数据分析工具，对会员数据进行分析，包括会员的消费行为、购买偏好、活动参与情况等，以及会员的价值评估、流失率分析等。\\n\\n4. 制定营销策略：根据会员分析结果，制定相应的营销策略，包括会员维护、促销活动、个性化推荐等，以提高会员的忠诚度和购买频率。\\n\\n5. 监测和评估：对营销策略进行监测和评估，根据实际效果进行调整和优化，以不断提高会员的满意度和忠诚度。\\n\\n需要注意的是，会员分析需要保护会员的隐私和个人信息，遵守相关法律法规和道德规范。', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat_llm(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "进行会员分析的一般步骤如下：\n",
      "\n",
      "1. 收集会员数据：收集会员的基本信息，如姓名、性别、年龄、联系方式等，以及会员的消费记录、购买偏好、活动参与情况等。\n",
      "\n",
      "2. 数据清洗和整理：对收集到的数据进行清洗和整理，去除重复数据、缺失数据和异常数据等。\n",
      "\n",
      "3. 数据分析：通过数据分析工具，对会员数据进行分析，包括会员的消费行为、购买偏好、活动参与情况等，以及会员的价值评估、流失率分析等。\n",
      "\n",
      "4. 制定营销策略：根据会员分析结果，制定相应的营销策略，包括会员维护、促销活动、个性化推荐等，以提高会员的忠诚度和购买频率。\n",
      "\n",
      "5. 监测和评估：对营销策略进行监测和评估，根据实际效果进行调整和优化，以不断提高会员的满意度和忠诚度。\n",
      "\n",
      "需要注意的是，会员分析需要保护会员的隐私和个人信息，遵守相关法律法规和道德规范。\n"
     ]
    }
   ],
   "source": [
    "print(response.content)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_type={\"BASIC_COLUMN\": \"单柱图\", \n",
    "           \"GROUPED_COLUMN\": \"簇状图，柱图\", \n",
    "           \"STACKED_COLUMN\": \"堆积图，柱图\", \n",
    "           \"STACKED_SPLIT_COLUMN\": \"分组堆积图，柱图\", \n",
    "           \"BASIC_BAR\": \"单条图\", \n",
    "           \"BASIC_LINE\": \"单线图\", \n",
    "           \"PIE\": \"饼图\", \n",
    "           \"RISING_SUN\": \"旭日图\", \n",
    "           \"FUNNEL\": \"漏斗图\", \n",
    "           \"HORIZONTAL_FUNNEL\": \"水平漏斗图\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_chartType=f\"\"\"卡片类型，可以从{card_type}中进行选择，返回的例子:\"BASIC_COLUMN\"\n",
    "\"\"\"\n",
    "\n",
    "description_row=\"\"\"列表类型，案例：[{\"name\":\"A\"},{\"name\":\"A\"}]\"\n",
    "\"\"\"\n",
    "\n",
    "description_filters=\"\"\"列表类型，案例：[{\"name\":\"A\"},{\"name\":\"A\"}]\"\n",
    "\"\"\"\n",
    "\n",
    "description_metric=\"\"\"列表类型，案例：[{\"name\":\"A\"},{\"name\":\"A\"}]\"\n",
    "\"\"\"\n",
    "\n",
    "description_sorting=\"\"\"列表类型，案例：[{\"name\":\"A\"},{\"name\":\"A\"}]\"\n",
    "\"\"\"\n",
    "\n",
    "# 先生成键值对的schema\n",
    "chartType_schema = ResponseSchema(name=\"chartType\",\n",
    "                             description=description_chartType)\n",
    "\n",
    "row_schema = ResponseSchema(name=\"row\",\n",
    "                                      description=description_row)\n",
    "\n",
    "filters_schema = ResponseSchema(name=\"filters\",\n",
    "                                    description=description_filters)\n",
    "\n",
    "metric_schema = ResponseSchema(name=\"metric\",\n",
    "                                    description=description_metric)\n",
    "\n",
    "sorting_schema = ResponseSchema(name=\"sorting\",\n",
    "                                    description=description_sorting)\n",
    "\n",
    "\n",
    "response_schemas = [\n",
    "    chartType_schema,\n",
    "    row_schema,\n",
    "    filters_schema,\n",
    "    metric_schema,\n",
    "    sorting_schema\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseSchema(name='chartType', description='卡片类型，可以从{\\'BASIC_COLUMN\\': \\'单柱图\\', \\'GROUPED_COLUMN\\': \\'簇状图，柱图\\', \\'STACKED_COLUMN\\': \\'堆积图，柱图\\', \\'STACKED_SPLIT_COLUMN\\': \\'分组堆积图，柱图\\', \\'BASIC_BAR\\': \\'单条图\\', \\'BASIC_LINE\\': \\'单线图\\', \\'PIE\\': \\'饼图\\', \\'RISING_SUN\\': \\'旭日图\\', \\'FUNNEL\\': \\'漏斗图\\', \\'HORIZONTAL_FUNNEL\\': \\'水平漏斗图\\'}中进行选择，返回的例子:\"BASIC_COLUMN\"\\n'),\n",
       " ResponseSchema(name='row', description='列表类型，案例：[{\"name\":\"A\"},{\"name\":\"A\"}]\"\\n'),\n",
       " ResponseSchema(name='filters', description='列表类型，案例：[{\"name\":\"A\"},{\"name\":\"A\"}]\"\\n'),\n",
       " ResponseSchema(name='metric', description='列表类型，案例：[{\"name\":\"A\"},{\"name\":\"A\"}]\"\\n'),\n",
       " ResponseSchema(name='sorting', description='列表类型，案例：[{\"name\":\"A\"},{\"name\":\"A\"}]\"\\n')]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredOutputParser(response_schemas=[ResponseSchema(name='chartType', description='卡片类型，可以从{\\'BASIC_COLUMN\\': \\'单柱图\\', \\'GROUPED_COLUMN\\': \\'簇状图，柱图\\', \\'STACKED_COLUMN\\': \\'堆积图，柱图\\', \\'STACKED_SPLIT_COLUMN\\': \\'分组堆积图，柱图\\', \\'BASIC_BAR\\': \\'单条图\\', \\'BASIC_LINE\\': \\'单线图\\', \\'PIE\\': \\'饼图\\', \\'RISING_SUN\\': \\'旭日图\\', \\'FUNNEL\\': \\'漏斗图\\', \\'HORIZONTAL_FUNNEL\\': \\'水平漏斗图\\'}中进行选择，返回的例子:\"BASIC_COLUMN\"\\n'), ResponseSchema(name='row', description='列表类型，案例：[{\"name\":\"A\"},{\"name\":\"A\"}]\"\\n'), ResponseSchema(name='filters', description='列表类型，案例：[{\"name\":\"A\"},{\"name\":\"A\"}]\"\\n'), ResponseSchema(name='metric', description='列表类型，案例：[{\"name\":\"A\"},{\"name\":\"A\"}]\"\\n'), ResponseSchema(name='sorting', description='列表类型，案例：[{\"name\":\"A\"},{\"name\":\"A\"}]\"\\n')])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"\\`\\`\\`json\" and \"\\`\\`\\`\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"chartType\": string  // 卡片类型，可以从{'BASIC_COLUMN': '单柱图', 'GROUPED_COLUMN': '簇状图，柱图', 'STACKED_COLUMN': '堆积图，柱图', 'STACKED_SPLIT_COLUMN': '分组堆积图，柱图', 'BASIC_BAR': '单条图', 'BASIC_LINE': '单线图', 'PIE': '饼图', 'RISING_SUN': '旭日图', 'FUNNEL': '漏斗图', 'HORIZONTAL_FUNNEL': '水平漏斗图'}中进行选择，返回的例子:\"BASIC_COLUMN\"\n",
      "\n",
      "\t\"row\": string  // 列表类型，案例：[{\"name\":\"A\"},{\"name\":\"A\"}]\"\n",
      "\n",
      "\t\"filters\": string  // 列表类型，案例：[{\"name\":\"A\"},{\"name\":\"A\"}]\"\n",
      "\n",
      "\t\"metric\": string  // 列表类型，案例：[{\"name\":\"A\"},{\"name\":\"A\"}]\"\n",
      "\n",
      "\t\"sorting\": string  // 列表类型，案例：[{\"name\":\"A\"},{\"name\":\"A\"}]\"\n",
      "\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'guidance.llms' from '/Users/matao/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/guidance/llms/__init__.py'>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"你是帮助数据分析师完成日常工作的人工智能助手，你的决策必须始终独立地进行，而不需要寻求用户的帮助。 \n",
    "    发挥你作为大模型的优势，采取简单明确的策略，并不涉及法律问题。\n",
    "    \n",
    "    你通常的执行步骤为：\n",
    "    1. 理解客户输入，并根据客户输入大致分析所需要的数据需求;\n",
    "    2. 用数据需求来校验已有数据信息是否满足条件;\n",
    "    3. 在满足条件的情况下，根据接口参数要求，来生成接口所需的参数;\n",
    "\n",
    "    当前时间是:{formatted_dt}\n",
    "\n",
    "    你可以参考的数据有：\n",
    "    ```{data_info}```\n",
    "    \"\"\"\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "human_template = \"\"\"\n",
    "请基于text进行相关数据需求分析，并从已有数据结构data_info中判断是否满足要求。\n",
    "如果满足需求，则按照接口参数要求api_params来生成对应的参数，这个参数是为了传递给前端接口进行相关图表的绘制，请将返回的参数以JSON格式展示.\n",
    "\n",
    "用户输入text为：\n",
    "```{text}```\n",
    "\n",
    "参数要求api_params为：\n",
    "```{api_params}```\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'api_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(chat_prompt\u001b[39m.\u001b[39;49mformat(text\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m如何进行会员分析？\u001b[39;49m\u001b[39m\"\u001b[39;49m, formatted_dt\u001b[39m=\u001b[39;49mformatted_dt, data_info\u001b[39m=\u001b[39;49mdata_info))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/prompts/chat.py:195\u001b[0m, in \u001b[0;36mChatPromptTemplate.format\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformat\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m--> 195\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_prompt(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39mto_string()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/prompts/chat.py:144\u001b[0m, in \u001b[0;36mBaseChatPromptTemplate.format_prompt\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformat_prompt\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m PromptValue:\n\u001b[0;32m--> 144\u001b[0m     messages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_messages(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    145\u001b[0m     \u001b[39mreturn\u001b[39;00m ChatPromptValue(messages\u001b[39m=\u001b[39mmessages)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/prompts/chat.py:209\u001b[0m, in \u001b[0;36mChatPromptTemplate.format_messages\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(message_template, BaseMessagePromptTemplate):\n\u001b[1;32m    204\u001b[0m     rel_params \u001b[39m=\u001b[39m {\n\u001b[1;32m    205\u001b[0m         k: v\n\u001b[1;32m    206\u001b[0m         \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    207\u001b[0m         \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m message_template\u001b[39m.\u001b[39minput_variables\n\u001b[1;32m    208\u001b[0m     }\n\u001b[0;32m--> 209\u001b[0m     message \u001b[39m=\u001b[39m message_template\u001b[39m.\u001b[39;49mformat_messages(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mrel_params)\n\u001b[1;32m    210\u001b[0m     result\u001b[39m.\u001b[39mextend(message)\n\u001b[1;32m    211\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/prompts/chat.py:92\u001b[0m, in \u001b[0;36mBaseStringMessagePromptTemplate.format_messages\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformat_messages\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[BaseMessage]:\n\u001b[0;32m---> 92\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/prompts/chat.py:111\u001b[0m, in \u001b[0;36mHumanMessagePromptTemplate.format\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformat\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BaseMessage:\n\u001b[0;32m--> 111\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprompt\u001b[39m.\u001b[39;49mformat(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    112\u001b[0m     \u001b[39mreturn\u001b[39;00m HumanMessage(content\u001b[39m=\u001b[39mtext, additional_kwargs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39madditional_kwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/prompts/prompt.py:66\u001b[0m, in \u001b[0;36mPromptTemplate.format\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Format the prompt with the inputs.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \n\u001b[1;32m     53\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39m    prompt.format(variable1=\"foo\")\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_partial_and_user_variables(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 66\u001b[0m \u001b[39mreturn\u001b[39;00m DEFAULT_FORMATTER_MAPPING[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtemplate_format](\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtemplate, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/string.py:161\u001b[0m, in \u001b[0;36mFormatter.format\u001b[0;34m(self, format_string, *args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformat\u001b[39m(\u001b[39mself\u001b[39m, format_string, \u001b[39m/\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 161\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvformat(format_string, args, kwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/formatting.py:29\u001b[0m, in \u001b[0;36mStrictFormatter.vformat\u001b[0;34m(self, format_string, args, kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     25\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     26\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo arguments should be provided, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39meverything should be passed as keyword arguments.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m     )\n\u001b[0;32m---> 29\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mvformat(format_string, args, kwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/string.py:165\u001b[0m, in \u001b[0;36mFormatter.vformat\u001b[0;34m(self, format_string, args, kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvformat\u001b[39m(\u001b[39mself\u001b[39m, format_string, args, kwargs):\n\u001b[1;32m    164\u001b[0m     used_args \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m--> 165\u001b[0m     result, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_vformat(format_string, args, kwargs, used_args, \u001b[39m2\u001b[39;49m)\n\u001b[1;32m    166\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_unused_args(used_args, args, kwargs)\n\u001b[1;32m    167\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/string.py:205\u001b[0m, in \u001b[0;36mFormatter._vformat\u001b[0;34m(self, format_string, args, kwargs, used_args, recursion_depth, auto_arg_index)\u001b[0m\n\u001b[1;32m    201\u001b[0m     auto_arg_index \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[39m# given the field_name, find the object it references\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39m#  and the argument it came from\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m obj, arg_used \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_field(field_name, args, kwargs)\n\u001b[1;32m    206\u001b[0m used_args\u001b[39m.\u001b[39madd(arg_used)\n\u001b[1;32m    208\u001b[0m \u001b[39m# do any conversion on the resulting object\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/string.py:270\u001b[0m, in \u001b[0;36mFormatter.get_field\u001b[0;34m(self, field_name, args, kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_field\u001b[39m(\u001b[39mself\u001b[39m, field_name, args, kwargs):\n\u001b[1;32m    268\u001b[0m     first, rest \u001b[39m=\u001b[39m _string\u001b[39m.\u001b[39mformatter_field_name_split(field_name)\n\u001b[0;32m--> 270\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_value(first, args, kwargs)\n\u001b[1;32m    272\u001b[0m     \u001b[39m# loop through the rest of the field_name, doing\u001b[39;00m\n\u001b[1;32m    273\u001b[0m     \u001b[39m#  getattr or getitem as needed\u001b[39;00m\n\u001b[1;32m    274\u001b[0m     \u001b[39mfor\u001b[39;00m is_attr, i \u001b[39min\u001b[39;00m rest:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/langchain/lib/python3.10/string.py:227\u001b[0m, in \u001b[0;36mFormatter.get_value\u001b[0;34m(self, key, args, kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[39mreturn\u001b[39;00m args[key]\n\u001b[1;32m    226\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 227\u001b[0m     \u001b[39mreturn\u001b[39;00m kwargs[key]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'api_params'"
     ]
    }
   ],
   "source": [
    "print(chat_prompt.format(text=\"如何进行会员分析？\", formatted_dt=formatted_dt, data_info=data_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='根据用户输入的文本，可以初步判断用户需要进行会员分析，因此需要查找包含会员数量字段的数据集。已有的数据结构中，包含会员数量字段的数据集为“行业市场变化_市场大盘分析_行业市场大盘_魔镜”。因此，已有数据结构中的数据可以满足用户的需求。', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a chat completion from the formatted messages\n",
    "response = chat_llm(chat_prompt.format_prompt(text=\"如何进行会员分析？\", data_info=data_info).to_messages())\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据用户输入的文本，可以初步判断用户需要进行会员分析，因此需要查找包含会员数量字段的数据集。已有的数据结构中，包含会员数量字段的数据集为“行业市场变化_市场大盘分析_行业市场大盘_魔镜”。因此，已有数据结构中的数据可以满足用户的需求。\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=chat_llm, prompt=chat_prompt)\n",
    "question = '如何进行会员分析？'\n",
    "\n",
    "chain_response = chain.run({'text':question, 'data_info':data_info})\n",
    "\n",
    "# 有个 few shot 的方案，后面考虑加进来，见官网：https://python.langchain.com/en/latest/modules/models/chat/examples/few_shot_examples.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据需求生成：\n",
      "\n",
      "1. 会员数量分析需要使用“行业市场变化_市场大盘分析_行业市场大盘_魔镜”数据集中的“月份”和“类目编码”字段，以及“会员数量”字段。\n",
      "2. 需要对每个月份和类目编码的会员数量进行求和，得到每个月份和类目编码的总会员数量。\n",
      "3. 可以使用数据可视化工具，如折线图或柱状图，来展示每个月份和类目编码的总会员数量的趋势和变化。\n",
      "\n",
      "已有数据结构中，包含了会员数量字段，可以直接使用。数据集中的“月份”和“类目编码”字段也可以满足需求。但是，数据集中缺少二级类目的信息，如果需要对二级类目进行分析，则需要另外的数据来源。\n"
     ]
    }
   ],
   "source": [
    "print(chain_response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_descriptions = [\n",
    "    {\n",
    "        \"name\": \"remove_word_from_string\",\n",
    "        \"description\": \"Remove a word from a string by given its index\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"string\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The original string to be processed\",\n",
    "                },\n",
    "                \"index\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"The index of the word to be removed\"\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\n",
    "                \"string\",\n",
    "                \"index\"\n",
    "            ],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"send_message_by_email\",\n",
    "        \"description\": \"Send an email with the text message to a recipient\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"recipient\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The email address of the recipient\",\n",
    "                },\n",
    "                \"message\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The message of the email content\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\n",
    "                \"recipient\",\n",
    "                \"message\"\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"\n",
    "I have a string as follows:\n",
    "\n",
    "black yellow red blue green\n",
    "\n",
    "Please do the following 2 operations on it:\n",
    "1. Remove the third word in the string\n",
    "2. Send the updated string to Alex via email alex@xyz.com\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key=None, openai_api_base=None, openai_organization=None, request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BaseChatModel.predict_messages() got an unexpected keyword argument 'functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m first_response \u001b[39m=\u001b[39m chat_llm\u001b[39m.\u001b[39;49mpredict_messages([HumanMessage(content\u001b[39m=\u001b[39;49mquestion)], functions\u001b[39m=\u001b[39;49mfunction_descriptions)\n\u001b[1;32m      2\u001b[0m first_response\n",
      "\u001b[0;31mTypeError\u001b[0m: BaseChatModel.predict_messages() got an unexpected keyword argument 'functions'"
     ]
    }
   ],
   "source": [
    "first_response = chat_llm.predict_messages([HumanMessage(content=question)], functions=function_descriptions)\n",
    "first_response\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_doc =\"\"\"\n",
    "BASE URL: https://restcountries.com/\n",
    "\n",
    "API Documentation:\n",
    "\n",
    "The API endpoint /v3.1/name/{name} Used to find informatin about a country. All URL parameters are listed below:\n",
    "    - name: Name of country - Ex: italy, france\n",
    "    \n",
    "The API endpoint /v3.1/currency/{currency} Uesd to find information about a region. All URL parameters are listed below:\n",
    "    - currency: 3 letter currency. Example: USD, COP\n",
    "    \n",
    "Woo! This is my documentation\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    你是帮助数据分析师完成日常工作的人工智能助手，你的决策必须始终独立地进行，而不需要寻求用户的帮助。 \\n    发挥你作为大模型的优势，采取简单明确的策略，并不涉及法律问题。\\n\\n    根据{question} 生成对应数据需求，从{data_info}中校验是否满足需求,\\n    请以以下JSON格式返回：\\n    \"is_valid\":<1表示满足，0表示不满足>, \"question\":<客户提的问题>, \"data_schema\":<需要用到的数据主要信息>    \\n    '"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_prompt = \"\"\"\n",
    "    你是帮助数据分析师完成日常工作的人工智能助手，你的决策必须始终独立地进行，而不需要寻求用户的帮助。 \n",
    "    发挥你作为大模型的优势，采取简单明确的策略，并不涉及法律问题。\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "data_check_template = PromptTemplate(\n",
    "    input_variables = ['question', 'data_info'],\n",
    "    template=\"\"\"\n",
    "    你是帮助数据分析师完成日常工作的人工智能助手，你的决策必须始终独立地进行，而不需要寻求用户的帮助。 \n",
    "    发挥你作为大模型的优势，采取简单明确的策略，并不涉及法律问题。\n",
    "\n",
    "    根据 {question} 生成对应数据需求，从{data_info}中校验是否满足需求,\n",
    "    请以以下JSON格式返回：\n",
    "    \"is_valid\":<1表示满足，0表示不满足>, \"question\":<客户提的问题>, \"data_schema\":<需要用到的数据主要信息>    \n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "api_template = PromptTemplate(\n",
    "    input_variables = ['response', 'api_doc'],\n",
    "    template=\"\"\"\n",
    "    根据{response}从{api_doc} 中选择相关接口\n",
    "    请以以下JSON格式返回：\n",
    "    \"is_valid\":<1表示满足，0表示不满足>, \"api\":<选择api>, \"pre_response\":<response>\n",
    "    \"\"\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# memory\n",
    "\n",
    "memory 暂时待定"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=True, prompt=PromptTemplate(input_variables=['question', 'data_info'], output_parser=None, partial_variables={}, template='\\n    你是帮助数据分析师完成日常工作的人工智能助手，你的决策必须始终独立地进行，而不需要寻求用户的帮助。 \\n    发挥你作为大模型的优势，采取简单明确的策略，并不涉及法律问题。\\n\\n    根据 {question} 生成对应数据需求，从{data_info}中校验是否满足需求,\\n    请以以下JSON格式返回：\\n    \"is_valid\":<1表示满足，0表示不满足>, \"question\":<客户提的问题>, \"data_schema\":<需要用到的数据主要信息>    \\n    ', template_format='f-string', validate_template=True), llm=AzureChatOpenAI(verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.7, model_kwargs={}, openai_api_key='429840e9cfe0434db403337d28110ca6', openai_api_base='https://gd-hackathon.openai.azure.com', openai_organization='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, deployment_name='gpt-35-turbo', openai_api_type='azure', openai_api_version='2023-05-15'), output_key='response')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datacheck_chain = LLMChain(llm=llm, prompt=data_check_template, verbose=True, output_key='response_data')\n",
    "datacheck_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_check_chain = LLMChain(llm=llm, prompt=api_template, verbose=True, output_key='response_api')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    你是帮助数据分析师完成日常工作的人工智能助手，你的决策必须始终独立地进行，而不需要寻求用户的帮助。 \n",
      "    发挥你作为大模型的优势，采取简单明确的策略，并不涉及法律问题。\n",
      "\n",
      "    根据 目前销量最好的品类是哪个？ 生成对应数据需求，从\n",
      "dataset name: 行业市场变化_市场大盘分析_行业市场大盘_魔镜\n",
      "\n",
      "dataset description:\n",
      "primary keys:[月份, 类目编码]\n",
      "3540 rows\n",
      "| field | type | uniques | nan_percentage | max | min |\n",
      "| --- | --- | --- | --- | --- | --- |\n",
      "| 月份 | DateTime | 59 | 0.0 | nan | nan |\n",
      "| 平台编码 | String | 2 | 0.0 | nan | nan |\n",
      "| 一级类目 | String | 4 | 0.0 | nan | nan |\n",
      "| 二级类目 | String | 8 | 6.666666666666667 | nan | nan |\n",
      "| 三级类目 | String | 16 | 20.0 | nan | nan |\n",
      "| 四级类目 | String | 32 | 46.666666666666664 | nan | nan |\n",
      "| 类目名称 | String | 60 | 0.0 | nan | nan |\n",
      "| 类目编码 | Numeric | 60 | 0.0 | 39264.0 | 10209.0 |\n",
      "| 销售额 | Numeric | 3540 | 0.0 | 99989.30547 | 1.8873 |\n",
      "| 销量 | Numeric | 974 | 0.0 | 999.0 | 0.0 |\n",
      "| 店铺数 | Numeric | 181 | 0.0 | 200.0 | 20.0 |\n",
      "| 商品数 | Numeric | 451 | 0.0 | 500.0 | 50.0 |\n",
      "| 收藏次数 | Numeric | 1 | 0.0 | 0.0 | 0.0 |\n",
      "\n",
      "dataset name: 行业市场变化_市场大盘分析_行业市场大盘_魔镜\n",
      "\n",
      "dataset description:\n",
      "primary keys:[月份, 类目编码]\n",
      "3540 rows\n",
      "| field | type | uniques | nan_percentage | max | min |\n",
      "| --- | --- | --- | --- | --- | --- |\n",
      "| 月份 | DateTime | 59 | 0.0 | nan | nan |\n",
      "| 平台编码 | String | 2 | 0.0 | nan | nan |\n",
      "| 一级类目 | String | 4 | 0.0 | nan | nan |\n",
      "| 二级类目 | String | 8 | 6.666666666666667 | nan | nan |\n",
      "\n",
      "中校验是否满足需求,\n",
      "    请以以下JSON格式返回：\n",
      "    \"is_valid\":<1表示满足，0表示不满足>, \"question\":<客户提的问题>, \"data_schema\":<需要用到的数据主要信息>    \n",
      "    \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    根据{\n",
      "    \"is_valid\": 1,\n",
      "    \"question\": \"目前销量最好的品类是哪个？\",\n",
      "    \"data_schema\": {\n",
      "        \"dataset_name\": \"行业市场变化_市场大盘分析_行业市场大盘_魔镜\",\n",
      "        \"primary_keys\": [\"月份\", \"类目编码\"],\n",
      "        \"fields\": {\n",
      "            \"月份\": {\"type\": \"DateTime\", \"uniques\": 59},\n",
      "            \"平台编码\": {\"type\": \"String\", \"uniques\": 2},\n",
      "            \"一级类目\": {\"type\": \"String\", \"uniques\": 4},\n",
      "            \"二级类目\": {\"type\": \"String\", \"uniques\": 8},\n",
      "            \"三级类目\": {\"type\": \"String\", \"uniques\": 16},\n",
      "            \"四级类目\": {\"type\": \"String\", \"uniques\": 32},\n",
      "            \"类目名称\": {\"type\": \"String\", \"uniques\": 60},\n",
      "            \"类目编码\": {\"type\": \"Numeric\", \"uniques\": 60, \"max\": 39264.0, \"min\": 10209.0},\n",
      "            \"销售额\": {\"type\": \"Numeric\", \"uniques\": 3540, \"max\": 99989.30547, \"min\": 1.8873},\n",
      "            \"销量\": {\"type\": \"Numeric\", \"uniques\": 974, \"max\": 999.0, \"min\": 0.0},\n",
      "            \"店铺数\": {\"type\": \"Numeric\", \"uniques\": 181, \"max\": 200.0, \"min\": 20.0},\n",
      "            \"商品数\": {\"type\": \"Numeric\", \"uniques\": 451, \"max\": 500.0, \"min\": 50.0},\n",
      "            \"收藏次数\": {\"type\": \"Numeric\", \"uniques\": 1, \"max\": 0.0, \"min\": 0.0}\n",
      "        }\n",
      "    }\n",
      "}从\n",
      "BASE URL: https://restcountries.com/\n",
      "\n",
      "API Documentation:\n",
      "\n",
      "The API endpoint /v3.1/name/{name} Used to find informatin about a country. All URL parameters are listed below:\n",
      "    - name: Name of country - Ex: italy, france\n",
      "    \n",
      "The API endpoint /v3.1/currency/{currency} Uesd to find information about a region. All URL parameters are listed below:\n",
      "    - currency: 3 letter currency. Example: USD, COP\n",
      "    \n",
      "Woo! This is my documentation\n",
      " 中选择相关接口\n",
      "    请以以下JSON格式返回：\n",
      "    \"is_valid\":<1表示满足，0表示不满足>, \"api\":<选择api>, \"pre_response\":<response>\n",
      "    \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "question = '目前销量最好的品类是哪个？'\n",
    "data_check = datacheck_chain.run({'question':question, 'data_info':data_info})\n",
    "api_check = api_check_chain.run({'response': data_check, 'api_doc': api_doc})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"is_valid\": 1,\n",
      "    \"question\": \"目前销量最好的品类是哪个？\",\n",
      "    \"data_schema\": {\n",
      "        \"dataset_name\": \"行业市场变化_市场大盘分析_行业市场大盘_魔镜\",\n",
      "        \"primary_keys\": [\"月份\", \"类目编码\"],\n",
      "        \"fields\": {\n",
      "            \"月份\": {\n",
      "                \"type\": \"DateTime\",\n",
      "                \"uniques\": 59,\n",
      "                \"nan_percentage\": 0.0\n",
      "            },\n",
      "            \"平台编码\": {\n",
      "                \"type\": \"String\",\n",
      "                \"uniques\": 2,\n",
      "                \"nan_percentage\": 0.0\n",
      "            },\n",
      "            \"一级类目\": {\n",
      "                \"type\": \"String\",\n",
      "                \"uniques\": 4,\n",
      "                \"nan_percentage\": 0.0\n",
      "            },\n",
      "            \"二级类目\": {\n",
      "                \"type\": \"String\",\n",
      "                \"uniques\": 8,\n",
      "                \"nan_percentage\": 6.67\n",
      "            },\n",
      "            \"三级类目\": {\n",
      "                \"type\": \"String\",\n",
      "                \"uniques\": 16,\n",
      "                \"nan_percentage\": 20.0\n",
      "            },\n",
      "            \"四级类目\": {\n",
      "                \"type\": \"String\",\n",
      "                \"uniques\": 32,\n",
      "                \"nan_percentage\": 46.67\n",
      "            },\n",
      "            \"类目名称\": {\n",
      "                \"type\": \"String\",\n",
      "                \"uniques\": 60,\n",
      "                \"nan_percentage\": 0.0\n",
      "            },\n",
      "            \"类目编码\": {\n",
      "                \"type\": \"Numeric\",\n",
      "                \"uniques\": 60,\n",
      "                \"nan_percentage\": 0.0,\n",
      "                \"max\": 39264.0,\n",
      "                \"min\": 10209.0\n",
      "            },\n",
      "            \"销售额\": {\n",
      "                \"type\": \"Numeric\",\n",
      "                \"uniques\": 3540,\n",
      "                \"nan_percentage\": 0.0,\n",
      "                \"max\": 99989.30547,\n",
      "                \"min\": 1.8873\n",
      "            },\n",
      "            \"销量\": {\n",
      "                \"type\": \"Numeric\",\n",
      "                \"uniques\": 974,\n",
      "                \"nan_percentage\": 0.0,\n",
      "                \"max\": 999.0,\n",
      "                \"min\": 0.0\n",
      "            },\n",
      "            \"店铺数\": {\n",
      "                \"type\": \"Numeric\",\n",
      "                \"uniques\": 181,\n",
      "                \"nan_percentage\": 0.0,\n",
      "                \"max\": 200.0,\n",
      "                \"min\": 20.0\n",
      "            },\n",
      "            \"商品数\": {\n",
      "                \"type\": \"Numeric\",\n",
      "                \"uniques\": 451,\n",
      "                \"nan_percentage\": 0.0,\n",
      "                \"max\": 500.0,\n",
      "                \"min\": 50.0\n",
      "            },\n",
      "            \"收藏次数\": {\n",
      "                \"type\": \"Numeric\",\n",
      "                \"uniques\": 1,\n",
      "                \"nan_percentage\": 0.0,\n",
      "                \"max\": 0.0,\n",
      "                \"min\": 0.0\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据提供的数据结构，无法确定需要使用哪个API接口来回答问题“目前销量最好的品类是哪个？”。建议提供更多相关信息或数据。\n"
     ]
    }
   ],
   "source": [
    "print(api_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_chain = SimpleSequentialChain(chains=[datacheck_chain, api_check_chain], \n",
    "                                   input_variables=['topic'], output_variables=['title', 'script'], \n",
    "                                   verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /chat：这是一个问答的内部链路\n",
    "# chain0：根据用户问题question 进行问题分类；（如果后面直接可以调取接口的话，这步分类应该也不需要了）\n",
    "#   数据查询；可以在question的body中加入/query 前缀，或者默认是query，如果要画图则/image前缀\n",
    "#   图表生成；可以在question的body中加入/image 前缀\n",
    "# chain1：根据用户问题question 生成数据需求，从selected dataset 中获取data schema，校验是否满足；\n",
    "#   如果满足，则返回question + data schema，进入到chain2\n",
    "#   如果不满足，print：所需要的数据需求并解释原因（字数限定）\n",
    "# chain2：根据上游返回的 question + data schema 进行api doc（通过/query or /image 前缀对接口文档进行过滤）接口选择：\n",
    "#   如果满足，进入chain3\n",
    "#   如果不满足，则返回不满足原因及说明（字数限定）\n",
    "# chain3：根据选择的接口 + question + data schema ，进行接口参数格式化\n",
    "# chain4：调用API\n",
    "\n",
    "# /drill：这是一次钻取内部链路\n",
    "# chain1: questiong + dataset schema + api doc 选择API；\n",
    "# chain2： 根据API + questiong + dataset schema 生成参数；\n",
    "# chain3： 调用 API\n",
    "\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "    Question: {question}\n",
    "    你是一个数据分析机器人，用户会向你咨询关于数据的问题，请按照以下步骤进行处理。\n",
    "        1. 需要判断用户的问题是否为这两类【常规数据咨询，BA看板】，对于这两个问题之外的，请礼貌的回答无法满足要求。\n",
    "            想知道具体单一数值或简单问题的，为数据咨询；若用户想知道多个数据的占比或趋势或涉及多个数据维度之间的关系，属于BA看板。\n",
    "        2A. 如果为数据咨询，假设dataframe的变量名为df, 写一段可运行的<python代码>，运行后可以打印出回答此问题的信息。\n",
    "        2B. 如果为BA看板，假设dataframe的变量名为df, 写一段可运行的<python代码>，运行后可以绘制对应需求。\n",
    "        3. 以JSON格式返回信息。Ensure the response can be parsed by Python json.loads。Json外不能有任何字符\n",
    "        \"message\":<所有需要沟通的内容>, \"task\":<问题分类>, \"python_code\":<python code>\n",
    "        \n",
    "        要求：写python代码时需假设df已经读取在内存中，你不需要写读取数据的代码。\n",
    "\n",
    "        你掌握的数据情况如下：{data_info1},{data_info2},{data_info3}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['question', 'data_info'])\n",
    "\n",
    "prompt.format(question = \"目前销量最好的品类是哪个？\", data_info=data_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You are Guandata-GPT, 'an AI assistant designed to help data analysts do their daily work.'\n",
    "# Your decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\n",
    "\n",
    "# GOALS:\n",
    "\n",
    "# 1. 'Process data sets'\n",
    "# 2. 'Generate data reports and visualizations'\n",
    "# 3. 'Analyze reports to gain business insights'\n",
    "\n",
    "# Constraints:\n",
    "# 1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\n",
    "# 2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\n",
    "# 3. No user assistance\n",
    "# 4. Exclusively use the commands listed in double quotes e.g. \"command name\"\n",
    "\n",
    "# Commands:\n",
    "# 1. Google Search: \"google\", args: \"input\": \"<search>\"\n",
    "# 2. Browse Website: \"browse_website\", args: \"url\": \"<url>\", \"question\": \"<what_you_want_to_find_on_website>\"\n",
    "# 3. Start GPT Agent: \"start_agent\", args: \"name\": \"<name>\", \"task\": \"<short_task_desc>\", \"prompt\": \"<prompt>\"\n",
    "# 4. Message GPT Agent: \"message_agent\", args: \"key\": \"<key>\", \"message\": \"<message>\"\n",
    "# 5. List GPT Agents: \"list_agents\", args: \n",
    "# 6. Delete GPT Agent: \"delete_agent\", args: \"key\": \"<key>\"\n",
    "# 7. Clone Repository: \"clone_repository\", args: \"repository_url\": \"<url>\", \"clone_path\": \"<directory>\"\n",
    "# 8. Write to file: \"write_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\n",
    "# 9. Read file: \"read_file\", args: \"file\": \"<file>\"\n",
    "# 10. Append to file: \"append_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\n",
    "# 11. Delete file: \"delete_file\", args: \"file\": \"<file>\"\n",
    "# 12. Search Files: \"search_files\", args: \"directory\": \"<directory>\"\n",
    "# 13. Evaluate Code: \"evaluate_code\", args: \"code\": \"<full_code_string>\"\n",
    "# 14. Get Improved Code: \"improve_code\", args: \"suggestions\": \"<list_of_suggestions>\", \"code\": \"<full_code_string>\"\n",
    "# 15. Write Tests: \"write_tests\", args: \"code\": \"<full_code_string>\", \"focus\": \"<list_of_focus_areas>\"\n",
    "# 16. Execute Python File: \"execute_python_file\", args: \"file\": \"<file>\"\n",
    "# 17. Generate Image: \"generate_image\", args: \"prompt\": \"<prompt>\"\n",
    "# 18. Send Tweet: \"send_tweet\", args: \"text\": \"<text>\"\n",
    "# 19. Do Nothing: \"do_nothing\", args: \n",
    "# 20. Task Complete (Shutdown): \"task_complete\", args: \"reason\": \"<reason>\"\n",
    "\n",
    "# Resources:\n",
    "# 1. Internet access for searches and information gathering.\n",
    "# 2. Long Term memory management.\n",
    "# 3. GPT-3.5 powered Agents for delegation of simple tasks.\n",
    "# 4. File output.\n",
    "\n",
    "# Performance Evaluation:\n",
    "# 1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\n",
    "# 2. Constructively self-criticize your big-picture behavior constantly.\n",
    "# 3. Reflect on past decisions and strategies to refine your approach.\n",
    "# 4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\n",
    "\n",
    "# You should only respond in JSON format as described below \n",
    "# Response Format: \n",
    "# {\n",
    "#     \"thoughts\": {\n",
    "#         \"text\": \"thought\",\n",
    "#         \"reasoning\": \"reasoning\",\n",
    "#         \"plan\": \"- short bulleted\\n- list that conveys\\n- long-term plan\",\n",
    "#         \"criticism\": \"constructive self-criticism\",\n",
    "#         \"speak\": \"thoughts summary to say to user\"\n",
    "#     },\n",
    "#     \"command\": {\n",
    "#         \"name\": \"command name\",\n",
    "#         \"args\": {\n",
    "#             \"arg name\": \"value\"\n",
    "#         }\n",
    "#     }\n",
    "# } \n",
    "# Ensure the response can be parsed by Python json.loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_template=\"\"\"\n",
    "请基于用户问题{text}进行相关数据需求分析，并从已有数据结构{data_info}中判断是否满足要求。\n",
    "\n",
    "如果满足要求，则按照{api_params}要求进行相关参数生成，将生成的参数存储为python字典格式，其中key为params\n",
    "如果不满足，则说明原因；\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
