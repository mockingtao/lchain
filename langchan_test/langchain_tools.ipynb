{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from apikey import apikey, serpapi_key, API_KEY, BASE_URL, DEPLOYMENT_NAME\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "os.environ['SERPAPI_API_KEY'] = serpapi_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_azure = AzureChatOpenAI(\n",
    "    openai_api_base=BASE_URL,\n",
    "    openai_api_version=\"2023-05-15\",\n",
    "    deployment_name=DEPLOYMENT_NAME,\n",
    "    openai_api_key=API_KEY,\n",
    "    openai_api_type = \"azure\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='我喜欢编程。', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_azure([HumanMessage(content=\"Translate this sentence from English to Chinese. I love programming.\")])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义Tools\n",
    "\n",
    "创建Tool 必要组件：\n",
    "- name (str), is required and must be unique within a set of tools provided to an agent\n",
    "- description (str), is optional but recommended, as it is used by an agent to determine tool use\n",
    "- return_direct (bool), defaults to False\n",
    "- args_schema (Pydantic BaseModel), is optional but recommended, can be used to provide more information (e.g., few-shot examples) or validation for expected parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMMathChain, SerpAPIWrapper\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import BaseTool, StructuredTool, Tool, tool\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completely New Tools - String Input and Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方法一：Tool dataclass -- 从工具库中直接引用工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matao/opt/anaconda3/envs/langchain/lib/python3.10/site-packages/langchain/chains/llm_math/base.py:50: UserWarning: Directly instantiating an LLMMathChain with an llm is deprecated. Please instantiate with llm_chain argument or using the from_llm class method.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "search = SerpAPIWrapper()\n",
    "llm_math_chain = LLMMathChain(llm=llm_azure, verbose=True)\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        func=search.run,\n",
    "        name=\"search\",\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class CalculatorInput(BaseModel):\n",
    "    question: str = Field()\n",
    "\n",
    "tools.append(\n",
    "    Tool.from_function(\n",
    "        func=llm_math_chain.run,\n",
    "        name=\"Calculator\",\n",
    "        description=\"useful for when you need to answer questions about math\",\n",
    "        args_schema=CalculatorInput\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='search', description='useful for when you need to answer questions about current events', args_schema=None, return_direct=False, verbose=False, callbacks=None, callback_manager=None, handle_tool_error=False, func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'google_domain': 'google.com', 'gl': 'us', 'hl': 'en'}, serpapi_api_key='abc98e5936b29895645aabf66c3e65cbc9693d18166c27eba62a0399f75e8562', aiosession=None)>, coroutine=None)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    tools, llm_azure, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方法二：Subclassing the BaseTool class - 从BaseTool 从继承一个子类\n",
    "\n",
    "可以直接子类化 BaseTool。如果希望对实例变量有更多的控制，或者希望将回调传播到嵌套链或其他工具，那么这很有用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Type\n",
    "\n",
    "from langchain.callbacks.manager import(\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun\n",
    ")\n",
    "\n",
    "class CustomSearchTool(BaseTool):\n",
    "    name = \"custome_search\"\n",
    "    description = \"useful for when you need to answer questions about current events\"\n",
    "\n",
    "    def _run(\n",
    "            self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        return search.run(query)\n",
    "    \n",
    "    async def _arun(\n",
    "            self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"custom_search does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCalculatorTool(BaseTool):\n",
    "    name = \"Calculator\"\n",
    "    description = \"useful for when you need to answer questions about math\"\n",
    "    args_schema: Type[BaseModel] = CalculatorInput\n",
    "\n",
    "    def _run(\n",
    "            self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        return llm_math_chain.run(query)\n",
    "    \n",
    "    async def _arun(\n",
    "            self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"Calculator does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [CustomSearchTool(), CustomCalculatorTool()]\n",
    "agent = initialize_agent(\n",
    "    tools, llm_azure, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 tool 装饰器\n",
    "\n",
    "还是推荐这个方式进行工具创建，非常快捷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='search_api', description='search_api(query: str) -> str - searches the API for the query.', args_schema=<class 'pydantic.main.search_apiSchemaSchema'>, return_direct=False, verbose=False, callbacks=None, callback_manager=None, handle_tool_error=False, func=<function search_api at 0x12372d120>, coroutine=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def search_api(query: str) -> str:\n",
    "    \"\"\"searches the API for the query.\"\"\"\n",
    "    return f\"Results for query {query}\"\n",
    "\n",
    "search_api"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "装饰器中传递参数可以重命名工具和 return_direct 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='search_re', description='search_re(query: str) -> str - Searches the API for the query.', args_schema=<class 'pydantic.main.search_reSchemaSchema'>, return_direct=True, verbose=False, callbacks=None, callback_manager=None, handle_tool_error=False, func=<function search_api at 0x12372e5f0>, coroutine=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tool(\"search_re\", return_direct=True)\n",
    "def search_api(query: str) -> str:\n",
    "    \"\"\"Searches the API for the query.\"\"\"\n",
    "    return \"Results\"\n",
    "\n",
    "search_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='search', description='search(query: str) -> str - Searches the API for the query.', args_schema=<class '__main__.SearchInput'>, return_direct=True, verbose=False, callbacks=None, callback_manager=None, handle_tool_error=False, func=<function search_api at 0x12372c5e0>, coroutine=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SearchInput(BaseModel):\n",
    "    query: str = Field(description=\"should be a search query\")\n",
    "\n",
    "@tool(\"search\", return_direct=True, args_schema=SearchInput)\n",
    "def search_api(query: str) -> str:\n",
    "    \"\"\"Searches the API for the query.\"\"\"\n",
    "    return \"Results\"\n",
    "\n",
    "search_api"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义结构工具 - Structured Tools\n",
    "\n",
    "如果函数工具需要更多结构化参数，则可以使用 StructuredTool 类"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StructuredTool dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from langchain.tools import StructuredTool\n",
    "\n",
    "def post_message(url: str, body: dict, parameters: Optional[dict]=None) -> str:\n",
    "    \"\"\"Sends a POST request to the given url with the given body and parameters.\"\"\"\n",
    "    result = requests.post(url, json=body, params=parameters)\n",
    "    return f\"Status:{result.status_code} - {result.text}\"\n",
    "\n",
    "tool = StructuredTool.from_function(post_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='post_message', description='post_message(url: str, body: dict, parameters: Optional[dict] = None) -> str - Sends a POST request to the given url with the given body and parameters.', args_schema=<class 'pydantic.main.post_messageSchemaSchema'>, return_direct=False, verbose=False, callbacks=None, callback_manager=None, handle_tool_error=False, func=<function post_message at 0x12372eb00>, coroutine=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the priorities among Tools - 确定Tools之间的优先级"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Music Search\",\n",
    "        func=lambda x: \"'All I Want For Christmas Is You' by Mariah Carey.\",  # Mock Function\n",
    "        description=\"A Music search engine. Use this more than the normal search if the question is about Music, like 'who is the singer of yesterday?' or 'what is the most popular song in 2022?'\",\n",
    "        return_direct = True,\n",
    "    ),\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm_azure,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use Music Search for this question since it's about music.\n",
      "Action: Music Search\n",
      "Action Input: \"most famous christmas song\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m'All I Want For Christmas Is You' by Mariah Carey.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should double check to make sure this is accurate.\n",
      "Action: Music Search\n",
      "Action Input: \"most popular christmas song of all time\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m'All I Want For Christmas Is You' by Mariah Carey.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: 'All I Want For Christmas Is You' by Mariah Carey is the most famous Christmas song.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"'All I Want For Christmas Is You' by Mariah Carey is the most famous Christmas song.\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"what is the most famous song of christmas\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use Music Search for this question since it's about music.\n",
      "Action: Music Search\n",
      "Action Input: \"most famous christmas song\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m'All I Want For Christmas Is You' by Mariah Carey.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"'All I Want For Christmas Is You' by Mariah Carey.\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"what is the most famous song of christmas\")\n",
    "# cc：这次是设计return_direct=True 返回的结果，由此来看这里就没有Thought及后续，有结果即返回。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用工具直接返回结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Calculator\",\n",
    "        func=llm_math_chain.run,\n",
    "        description=\"useful for when you need to answer questions about math\",\n",
    "        return_direct=True,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理工具的Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.base import ToolException\n",
    "\n",
    "def _handle_error(error: ToolException) -> str:\n",
    "    return(\n",
    "        \"The following errors occurred during tool execution:\"\n",
    "        + error.args[0]\n",
    "        + \"Please try another tool.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tool1(s: str):\n",
    "    raise ToolException(\"The search tool1 is not available.\")\n",
    "\n",
    "def search_tool2(s: str):\n",
    "    raise ToolException(\"The search tool2 is not available.\")\n",
    "\n",
    "search_tool3 = SerpAPIWrapper()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"useful for when you need to answer questions about current events.You should give priority to using it.\"\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        func=search_tool1,\n",
    "        name=\"Search_tool1\",\n",
    "        description=description,\n",
    "        handle_tool_error=True,\n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        func=search_tool2,\n",
    "        name=\"Search_tool2\",\n",
    "        description=description,\n",
    "        handle_tool_error=_handle_error,\n",
    "    ),\n",
    "    Tool.from_function(\n",
    "        func=search_tool3.run,\n",
    "        name=\"Search_tool3\",\n",
    "        description=\"useful for when you need to answer questions about current events\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm_azure,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThis is a question about a current event, so I should prioritize using Search_tool1 or Search_tool2.\n",
      "Action: Search_tool1\n",
      "Action Input: \"Leo DiCaprio girlfriend\"\u001b[0m\n",
      "Observation: \u001b[31;1m\u001b[1;3mThe search tool1 is not available.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should try using Search_tool2 instead.\n",
      "Action: Search_tool2\n",
      "Action Input: \"Leo DiCaprio girlfriend\"\u001b[0m\n",
      "Observation: \u001b[31;1m\u001b[1;3mThe following errors occurred during tool execution:The search tool2 is not available.Please try another tool.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI should try using Search_tool3 instead.\n",
      "Action: Search_tool3\n",
      "Action Input: \"Leo DiCaprio girlfriend\"\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mThe actor is believed to have recently split from his girlfriend of five years, actor Camila Morrone, but has previously been romantically ...\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mBased on the observation, it seems that Leo DiCaprio's girlfriend is Camila Morrone, but they may have recently split up.\n",
      "Final Answer: Leo DiCaprio's girlfriend is Camila Morrone, but their current relationship status is unclear.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Leo DiCaprio's girlfriend is Camila Morrone, but their current relationship status is unclear.\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"Who is Leo DiCaprio's girlfriend?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
