{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import openai\n",
    "import json\n",
    "\n",
    "# Environment Variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from apikey import apikey \n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = apikey"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Vanilla Example\n",
    "\n",
    "Let's run through OpenAI's vanilla example of calling a weather API.\n",
    "\n",
    "First let's define our functions. This is the meat and potatoes of the new update\n",
    "\n",
    "Functions are specified with the following fields:\n",
    "\n",
    "* **Name:** The name of the function.\n",
    "* **Description:** A description of what the function does. The model will use this to decide when to call the function.\n",
    "* **Parameters:** The parameters object contains all of the input fields the function requires. These inputs can be of the following types: String, Number, Boolean, Object, Null, AnyOf. Refer to the API reference docs for details.\n",
    "* **Required:** Which of the parameters are required to make a query. The rest will be treated as optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_descriptions = [\n",
    "            {\n",
    "                \"name\": \"get_current_weather\",\n",
    "                \"description\": \"Get the current weather in a given location\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                        },\n",
    "                        \"unit\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The temperature unit to use. Infer this from the users location.\",\n",
    "                            \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"location\", \"unit\"],\n",
    "                },\n",
    "            }\n",
    "        ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's call the OpenAI API with this as a new parameter. Note: Make sure to use a model that can accept the function call. Here we are using `gpt-3.5-turbo-0613`.\n",
    "\n",
    "Let's first set a query that came from the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"What's the weather like in San Francisco?\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's set up our API call to OpenAI. Note: `function_call=\"auto\"` will allow the model to choose whether or not it responds with a function. You can set this to `none` if you *don't* want a function response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        \n",
    "        # This is the chat message from the user\n",
    "        messages=[{\"role\": \"user\", \"content\": user_query}],\n",
    "    \n",
    "        \n",
    "        functions=function_descriptions,\n",
    "        function_call=\"auto\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"content\": null,\n",
      "  \"function_call\": {\n",
      "    \"arguments\": \"{\\n  \\\"location\\\": \\\"San Francisco, CA\\\",\\n  \\\"unit\\\": \\\"celsius\\\"\\n}\",\n",
      "    \"name\": \"get_current_weather\"\n",
      "  },\n",
      "  \"role\": \"assistant\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "ai_response_message = response[\"choices\"][0][\"message\"]\n",
    "print(ai_response_message)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome, now we have our response w/ specific arguments called out.\n",
    "\n",
    "Let's clean up our response a bit better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'celsius'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_location = eval(ai_response_message['function_call']['arguments']).get(\"location\")\n",
    "user_unit = eval(ai_response_message['function_call']['arguments']).get(\"unit\")\n",
    "user_unit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's make a function that will serve as an interface to a dummy api call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_weather(location, unit):\n",
    "    \n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    \n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"72\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": [\"sunny\", \"windy\"],\n",
    "    }\n",
    "    return json.dumps(weather_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_response = get_current_weather(\n",
    "    location=user_location,\n",
    "    unit=user_unit,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"location\": \"San Francisco, CA\", \"temperature\": \"72\", \"unit\": \"celsius\", \"forecast\": [\"sunny\", \"windy\"]}'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our reponse from our service, we can pass this information back to our model for a natural language response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently, in San Francisco, CA, the weather is sunny and windy with a temperature of 72 degrees Celsius.\n"
     ]
    }
   ],
   "source": [
    "second_response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4-0613\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_query},\n",
    "        ai_response_message,\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"content\": function_response,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print (second_response['choices'][0]['message']['content'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain Support For Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage, ChatMessage\n",
    "from langchain.tools import format_tool_to_openai_function, YouTubeSearchTool, MoveFileTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0613\", openai_api_key=apikey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [MoveFileTool()]\n",
    "functions = [format_tool_to_openai_function(t) for t in tools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'move_file',\n",
       " 'description': 'Move or rename a file from one location to another',\n",
       " 'parameters': {'title': 'FileMoveInput',\n",
       "  'description': 'Input for MoveFileTool.',\n",
       "  'type': 'object',\n",
       "  'properties': {'source_path': {'title': 'Source Path',\n",
       "    'description': 'Path of the file to move',\n",
       "    'type': 'string'},\n",
       "   'destination_path': {'title': 'Destination Path',\n",
       "    'description': 'New path for the moved file',\n",
       "    'type': 'string'}},\n",
       "  'required': ['source_path', 'destination_path']}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "\t'name': 'move_file',\n",
    "\t'description': 'Move or rename a file from one location to another',\n",
    "\t'parameters': {\n",
    "\t\t'title': 'FileMoveInput',\n",
    "\t\t'description': 'Input for MoveFileTool.',\n",
    "\t\t'type': 'object',\n",
    "\t\t'properties': {\n",
    "\t\t\t'source_path': {\n",
    "\t\t\t\t'title': 'Source Path',\n",
    "\t\t\t\t'description': 'Path of the file to move',\n",
    "\t\t\t\t'type': 'string'\n",
    "\t\t\t},\n",
    "\t\t\t'destination_path': {\n",
    "\t\t\t\t'title': 'Destination Path',\n",
    "\t\t\t\t'description': 'New path for the moved file',\n",
    "\t\t\t\t'type': 'string'\n",
    "\t\t\t}\n",
    "\t\t},\n",
    "\t\t'required': ['source_path', 'destination_path']\n",
    "\t}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = llm.predict_messages([HumanMessage(content='move file foo to bar')], functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'move_file',\n",
       " 'arguments': '{\\n  \"source_path\": \"foo\",\\n  \"destination_path\": \"bar\"\\n}'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message.additional_kwargs['function_call']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另一个例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_descriptions = [\n",
    "            {\n",
    "                \"name\": \"edit_financial_forecast\",\n",
    "                \"description\": \"Make an edit to a users financial forecast model\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"year\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"description\": \"The year the user would like to make an edit to their forecast for\",\n",
    "                        },\n",
    "                        \"category\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The category of the edit a user would like to edit\"\n",
    "                        },\n",
    "                        \"amount\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"description\": \"The amount of units the user would like to change\"\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"year\", \"category\", \"amount\"],\n",
    "                },\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"print_financial_forecast\",\n",
    "                \"description\": \"Send the financial forecast to the printer\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"printer_name\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"the name of the printer that the forecast should be sent to\",\n",
    "                            \"enum\": [\"home_printer\", \"office_printer\"]\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"printer_name\"],\n",
    "                },\n",
    "            }\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_request = \"\"\"\n",
    "Please do three things add 40 units to 2023 headcount\n",
    "and subtract 23 units from 2022 opex\n",
    "then print out the forecast at my home\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'edit_financial_forecast', 'arguments': '{\\n  \"year\": 2023,\\n  \"category\": \"headcount\",\\n  \"amount\": 40\\n}'}}, example=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_response = llm.predict_messages([HumanMessage(content=user_request)],\n",
    "                                      functions=function_descriptions)\n",
    "first_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_call': {'name': 'edit_financial_forecast',\n",
       "  'arguments': '{\\n  \"year\": 2023,\\n  \"category\": \"headcount\",\\n  \"amount\": 40\\n}'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_response.additional_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'edit_financial_forecast'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_name = first_response.additional_kwargs[\"function_call\"][\"name\"]\n",
    "function_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Year: 2023\n",
      "Category: headcount\n",
      "Amount: 40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (f\"\"\"\n",
    "Year: {eval(first_response.additional_kwargs['function_call']['arguments']).get('year')}\n",
    "Category: {eval(first_response.additional_kwargs['function_call']['arguments']).get('category')}\n",
    "Amount: {eval(first_response.additional_kwargs['function_call']['arguments']).get('amount')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_response = llm.predict_messages([HumanMessage(content=user_request),\n",
    "                                        AIMessage(content=str(first_response.additional_kwargs)),\n",
    "                                        ChatMessage(role='function',\n",
    "                                                    additional_kwargs = {'name': function_name},\n",
    "                                                    content = \"Just updated the financial forecast for year 2023, category headcount amd amount 40\"\n",
    "                                                   )\n",
    "                                       ],\n",
    "                                       functions=function_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function_call': {'name': 'edit_financial_forecast',\n",
       "  'arguments': '{\\n  \"year\": 2022,\\n  \"category\": \"opex\",\\n  \"amount\": -23\\n}'}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_response.additional_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'edit_financial_forecast'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_name = second_response.additional_kwargs['function_call']['name']\n",
    "function_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "third_response = llm.predict_messages([HumanMessage(content=user_request),\n",
    "                                       AIMessage(content=str(first_response.additional_kwargs)),\n",
    "                                       AIMessage(content=str(second_response.additional_kwargs)),\n",
    "                                       ChatMessage(role='function',\n",
    "                                                    additional_kwargs = {'name': function_name},\n",
    "                                                    content = \"\"\"\n",
    "                                                        Just made the following updates: 2022, opex -23 and\n",
    "                                                        Year: 2023\n",
    "                                                        Category: headcount\n",
    "                                                        Amount: 40\n",
    "                                                    \"\"\"\n",
    "                                                   )\n",
    "                                       ],\n",
    "                                       functions=function_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "third_response.additional_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'function_call'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m function_name \u001b[39m=\u001b[39m third_response\u001b[39m.\u001b[39;49madditional_kwargs[\u001b[39m'\u001b[39;49m\u001b[39mfunction_call\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m function_name\n",
      "\u001b[0;31mKeyError\u001b[0m: 'function_call'"
     ]
    }
   ],
   "source": [
    "function_name = third_response.additional_kwargs['function_call']['name']\n",
    "function_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
