{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from apikey import apikey, langchain_apikey\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = apikey\n",
    "os.environ['LANGCHAIN_API_KEY'] = langchain_apikey\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run the example below, ensure the environment variable OPENAI_API_KEY is set\n",
    "import openai\n",
    "\n",
    "from langsmith.run_trees import RunTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be a user input to your app\n",
    "question = \"Can you summarize this morning's meetings?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a top-level run\n",
    "pipeline = RunTree(\n",
    "    name=\"Chat Pipeline\",\n",
    "    run_type=\"chain\",\n",
    "    inputs={\"question\": question}\n",
    ")\n",
    "\n",
    "# cc： 核心看来是在这个地方，通过RunTree 来进行“轨迹跟踪”，得到一个pipeline的对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunTree(id=UUID('53115abc-2476-4cff-87f2-7e4c099b68df'), name='Chat Pipeline', start_time=datetime.datetime(2024, 3, 18, 7, 49, 57, 368447, tzinfo=datetime.timezone.utc), run_type='chain', end_time=None, extra={}, error=None, serialized={'name': 'Chat Pipeline'}, events=None, inputs={'question': \"Can you summarize this morning's meetings?\"}, outputs=None, reference_example_id=None, parent_run_id=None, tags=None, parent_run=None, child_runs=[], session_name='default', session_id=None, client=Client (API URL: https://api.smith.langchain.com), dotted_order='20240318T074957368447Z53115abc-2476-4cff-87f2-7e4c099b68df', trace_id=UUID('53115abc-2476-4cff-87f2-7e4c099b68df'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"You are a helpful assistant. Please respond to the user's request only based on the given context.\"},\n",
       " {'role': 'user',\n",
       "  'content': \"Question: Can you summarize this morning's meetings?\\nContext: During this morning's meeting, we solved all world conflict.\"}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# This can be retrieved in a retrieval step\n",
    "context = \"During this morning's meeting, we solved all world conflict.\"\n",
    "\n",
    "messages = [\n",
    "    { \"role\": \"system\", \"content\": \"You are a helpful assistant. Please respond to the user's request only based on the given context.\" },\n",
    "    { \"role\": \"user\", \"content\": f\"Question: {question}\\nContext: {context}\"}\n",
    "]\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunTree(id=UUID('a6959c1f-1dcb-41c0-a50e-84493550dfee'), name='OpenAI Call', start_time=datetime.datetime(2024, 3, 18, 7, 51, 39, 322991, tzinfo=datetime.timezone.utc), run_type='llm', end_time=None, extra={}, error=None, serialized={'name': 'OpenAI Call'}, events=None, inputs={'messages': [{'role': 'system', 'content': \"You are a helpful assistant. Please respond to the user's request only based on the given context.\"}, {'role': 'user', 'content': \"Question: Can you summarize this morning's meetings?\\nContext: During this morning's meeting, we solved all world conflict.\"}]}, outputs={}, reference_example_id=None, parent_run_id=UUID('53115abc-2476-4cff-87f2-7e4c099b68df'), tags=None, parent_run=RunTree(id=UUID('53115abc-2476-4cff-87f2-7e4c099b68df'), name='Chat Pipeline', start_time=datetime.datetime(2024, 3, 18, 7, 49, 57, 368447, tzinfo=datetime.timezone.utc), run_type='chain', end_time=None, extra={}, error=None, serialized={'name': 'Chat Pipeline'}, events=None, inputs={'question': \"Can you summarize this morning's meetings?\"}, outputs=None, reference_example_id=None, parent_run_id=None, tags=None, parent_run=None, child_runs=[RunTree(id=UUID('a6959c1f-1dcb-41c0-a50e-84493550dfee'), name='OpenAI Call', start_time=datetime.datetime(2024, 3, 18, 7, 51, 39, 322991, tzinfo=datetime.timezone.utc), run_type='llm', end_time=None, extra={}, error=None, serialized={'name': 'OpenAI Call'}, events=None, inputs={'messages': [{'role': 'system', 'content': \"You are a helpful assistant. Please respond to the user's request only based on the given context.\"}, {'role': 'user', 'content': \"Question: Can you summarize this morning's meetings?\\nContext: During this morning's meeting, we solved all world conflict.\"}]}, outputs={}, reference_example_id=None, parent_run_id=UUID('53115abc-2476-4cff-87f2-7e4c099b68df'), tags=None, parent_run=RunTree(id=UUID('53115abc-2476-4cff-87f2-7e4c099b68df'), name='Chat Pipeline', start_time=datetime.datetime(2024, 3, 18, 7, 49, 57, 368447, tzinfo=datetime.timezone.utc), run_type='chain', end_time=None, extra={}, error=None, serialized={'name': 'Chat Pipeline'}, events=None, inputs={'question': \"Can you summarize this morning's meetings?\"}, outputs=None, reference_example_id=None, parent_run_id=None, tags=None, parent_run=None, child_runs=[...], session_name='default', session_id=None, client=Client (API URL: https://api.smith.langchain.com), dotted_order='20240318T074957368447Z53115abc-2476-4cff-87f2-7e4c099b68df', trace_id=UUID('53115abc-2476-4cff-87f2-7e4c099b68df')), child_runs=[], session_name='default', session_id=None, client=Client (API URL: https://api.smith.langchain.com), dotted_order='20240318T074957368447Z53115abc-2476-4cff-87f2-7e4c099b68df.20240318T075139322991Za6959c1f-1dcb-41c0-a50e-84493550dfee', trace_id=UUID('53115abc-2476-4cff-87f2-7e4c099b68df'))], session_name='default', session_id=None, client=Client (API URL: https://api.smith.langchain.com), dotted_order='20240318T074957368447Z53115abc-2476-4cff-87f2-7e4c099b68df', trace_id=UUID('53115abc-2476-4cff-87f2-7e4c099b68df')), child_runs=[], session_name='default', session_id=None, client=Client (API URL: https://api.smith.langchain.com), dotted_order='20240318T074957368447Z53115abc-2476-4cff-87f2-7e4c099b68df.20240318T075139322991Za6959c1f-1dcb-41c0-a50e-84493550dfee', trace_id=UUID('53115abc-2476-4cff-87f2-7e4c099b68df'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a child run\n",
    "child_llm_run = pipeline.create_child(\n",
    "    name=\"OpenAI Call\",\n",
    "    run_type=\"llm\",\n",
    "    inputs={\"messages\": messages},\n",
    ")\n",
    "\n",
    "child_llm_run\n",
    "\n",
    "# cc：这里就可以通过上文创建的pipeline对象来进行子链路创建。\n",
    "# 这只是一个例子，后面应该有更自动化的方式来进行子链路创建。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9425L5j9wDQXvgYljHecDmJxEXyla', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The meeting this morning achieved a significant milestone by resolving all world conflicts.', role='assistant', function_call=None, tool_calls=None))], created=1710748355, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_4f2ebda25a', usage=CompletionUsage(completion_tokens=14, prompt_tokens=55, total_tokens=69))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate a completion\n",
    "client = openai.Client()\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\", messages=messages\n",
    ")\n",
    "\n",
    "chat_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End the runs and log them\n",
    "child_llm_run.end(outputs=chat_completion)\n",
    "child_llm_run.post()\n",
    "\n",
    "pipeline.end(outputs={\"answer\": chat_completion.choices[0].message.content})\n",
    "pipeline.post()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
