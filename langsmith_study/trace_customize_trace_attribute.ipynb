{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "背景：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.path.dirname(os.path.realpath('__file__'))\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from apikey import apikey, langchain_apikey\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = apikey\n",
    "os.environ['LANGCHAIN_API_KEY'] = langchain_apikey\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.记录到特定项目\n",
    "\n",
    "如“概念”部分所述，LangSmith 使用项目的概念对Trace进行分组。\n",
    "\n",
    "如果未指定，则跟踪器项目将设置为default。您可以设置 LANGCHAIN_PROJECT 环境变量，以便为整个应用程序运行配置自定义项目名称。这应该在执行程序之前完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export LANGCHAIN_PROJECT=\"My Project\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.在运行时更改目标项目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当全局环境变量过于宽泛时，还可以在程序运行时设置项目名称。当您想要将跟踪记录到同一应用程序中的不同项目时，这很有用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI assistant.\"),\n",
    "    (\"user\", \"Question: {question}\")\n",
    "])\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1. 直接通过langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As of 2023, the estimated population of Canada is around 38 million people.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can set the project name for a specific tracer instance:\n",
    "from langchain.callbacks.tracers import LangChainTracer\n",
    "\n",
    "tracer = LangChainTracer(project_name=\"My Project\")\n",
    "\n",
    "question = \"How many people live in canada as of 2023?\"\n",
    "\n",
    "chain.invoke({\"question\": question}, config={\"callbacks\": [tracer]})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LangChain python also supports a context manager for tracing a specific block of code.\n",
    "# You can set the project name using the project_name parameter.\n",
    "from langchain_core.tracers.context import tracing_v2_enabled\n",
    "\n",
    "with tracing_v2_enabled(project_name=\"My Project\"):\n",
    "    chain.invoke({\"question\": \"How many people live in china as of 2023?\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2. 通过python SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I help you today?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "from langsmith import traceable\n",
    "from langsmith.run_trees import RunTree\n",
    "\n",
    "client = openai.Client()\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
    "]\n",
    "\n",
    "@traceable(\n",
    "    run_type=\"llm\",\n",
    "    name=\"OpenAI Call Decorator\",\n",
    ")\n",
    "def call_openai(\n",
    "    messages: list[dict], model: str = \"gpt-3.5-turbo\"\n",
    ") -> str:\n",
    "    return client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    ).choices[0].message.content\n",
    "\n",
    "# You can specify the Project via the project_name parameter\n",
    "call_openai(\n",
    "    messages,\n",
    "    langsmith_extra={\"project_name\": \"My Project\"},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.把metadata 和 tags 加入到traces中\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1. 通过langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The meaning of life is a complex and subjective concept that can vary greatly from person to person. Some may find meaning in personal relationships, fulfilling work, spiritual beliefs, or contributing to the greater good of society. Ultimately, the meaning of life is a deeply personal question that each individual must explore and determine for themselves.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "chat_model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = (prompt | chat_model | output_parser).with_config({\"tags\": [\"top-level-tag\"], \n",
    "                                                           \"metadata\": {\"top-level-key\": \"top-level-value\"}})\n",
    "\n",
    "\n",
    "chain.invoke({\"input\": \"What is the meaning of life?\"}, {\"tags\": [\"shared-tags\"], \"metadata\": {\"shared-key\": \"shared-value\"}})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.自定义Run name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.掩盖输入和输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "os.environ[\"LANGCHAIN_HIDE_INPUTS\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_HIDE_OUTPUTS\"] = \"true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tracers.context import tracing_v2_enabled\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langsmith import Client\n",
    "\n",
    "\n",
    "def filter_inputs(inputs: dict):\n",
    "    # You can define custom filtering here\n",
    "    return {}\n",
    "\n",
    "\n",
    "def filter_outputs(outputs: dict):\n",
    "    # You can define custom filtering here\n",
    "    return {}\n",
    "\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://smith.langchain.com/o/1040bdf6-7131-5c03-b7be-fb1b4779027f/projects/p/119422db-340f-4b6a-a8a1-303b804983a3/r/77f3af42-83da-488e-953c-60d3929cd251?poll=true\n",
      "https://smith.langchain.com/o/1040bdf6-7131-5c03-b7be-fb1b4779027f/projects/p/119422db-340f-4b6a-a8a1-303b804983a3/r/002e13d4-08c2-4285-ae8f-4be58c3103e3?poll=true\n"
     ]
    }
   ],
   "source": [
    "# You can configure tracing using the context manager below\n",
    "# or by directly creating a LangChainTracer object\n",
    "with tracing_v2_enabled(\n",
    "    \"test-filtering\",\n",
    "    client=Client(hide_inputs=filter_inputs, hide_outputs=filter_outputs),\n",
    ") as cb:\n",
    "    llm.invoke(\"Say foo\")\n",
    "    # The linked run will have its metadata present, but the inputs will be hidden\n",
    "    print(cb.get_run_url())\n",
    "\n",
    "with tracing_v2_enabled(\"test-filtering\", client=Client()) as cb:\n",
    "    llm.invoke(\"Say bar\")\n",
    "    # The linked run will not have hidden inputs and outputs\n",
    "    print(cb.get_run_url())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
